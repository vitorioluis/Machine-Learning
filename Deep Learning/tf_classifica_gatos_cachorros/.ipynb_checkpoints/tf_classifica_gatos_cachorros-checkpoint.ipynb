{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from glob import glob\n",
    "import zipfile\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow e tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caso queira salvar ou carregar o modelo\n",
    "import pickle\n",
    "nome_medelo = \"model_classificar_dog_cat.mod\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista arquivos por formato\n",
    "def filtrar_arquivo(tipo):\n",
    "    path = './'\n",
    "    lst_arq = os.listdir(path) # listando novamente o diret√≥rio para verificar arquivos csv\n",
    "    return [arq for arq in lst_arq if arq[-3:] == tipo]\n",
    "\n",
    "# Separa arquivo zip caso haja outros tipos de arquivo na pasta\n",
    "lst_zip = filtrar_arquivo('zip')\n",
    "\n",
    "# extrair arquivos do zip para trabalhar\n",
    "for zp in lst_zip:\n",
    "    fzp = zipfile.ZipFile(zp)\n",
    "    fzp.extractall('./') \n",
    "    fzp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dog = 0\n",
    "# cat = 1\n",
    "class_name = ['dog','cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_img_train = 'dataset/train/*.jpg'\n",
    "dir_img_test = 'dataset/test/*.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_img_array(lst):\n",
    "    \"\"\"\n",
    "    lista diretorios com imagens e convertem array\n",
    "    \n",
    "    \"\"\"\n",
    "    lst_img, lst_label=[],[]\n",
    "    for d in glob(lst):\n",
    "        lst_img.append(cv2.imread(d))\n",
    "        if 'dog' in d:\n",
    "            lst_label.append('0')\n",
    "        elif 'cat' in d:\n",
    "            lst_label.append('1')\n",
    "    return np.array(lst_img), np.array(lst_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gerando dados de trainos e test\n",
    "train_img, train_label = convert_img_array(dir_img_train)\n",
    "test_img, test_label = convert_img_array(dir_img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 32, 32, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 84,  97, 113],\n",
       "         [120, 133, 149],\n",
       "         [123, 132, 146],\n",
       "         ...,\n",
       "         [164, 156, 179],\n",
       "         [152, 140, 170],\n",
       "         [143, 129, 163]],\n",
       "\n",
       "        [[ 83,  96, 112],\n",
       "         [106, 119, 135],\n",
       "         [129, 140, 154],\n",
       "         ...,\n",
       "         [165, 158, 179],\n",
       "         [142, 132, 162],\n",
       "         [130, 119, 151]],\n",
       "\n",
       "        [[ 83,  99, 112],\n",
       "         [ 97, 110, 124],\n",
       "         [136, 147, 161],\n",
       "         ...,\n",
       "         [159, 157, 176],\n",
       "         [144, 139, 166],\n",
       "         [139, 134, 163]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[118,  86,  75],\n",
       "         [120,  80,  68],\n",
       "         [153,  97,  86],\n",
       "         ...,\n",
       "         [243, 238, 253],\n",
       "         [241, 232, 245],\n",
       "         [222, 212, 224]],\n",
       "\n",
       "        [[ 82,  47,  37],\n",
       "         [148, 106,  94],\n",
       "         [164, 105,  95],\n",
       "         ...,\n",
       "         [222, 217, 232],\n",
       "         [213, 203, 219],\n",
       "         [209, 199, 212]],\n",
       "\n",
       "        [[ 84,  49,  39],\n",
       "         [136,  94,  82],\n",
       "         [158,  97,  87],\n",
       "         ...,\n",
       "         [206, 200, 217],\n",
       "         [167, 157, 173],\n",
       "         [218, 207, 223]]],\n",
       "\n",
       "\n",
       "       [[[ 43,  84, 107],\n",
       "         [ 50,  89, 111],\n",
       "         [ 66, 103, 123],\n",
       "         ...,\n",
       "         [ 69, 121, 137],\n",
       "         [ 67, 121, 138],\n",
       "         [ 68, 122, 139]],\n",
       "\n",
       "        [[ 56,  95, 117],\n",
       "         [ 66, 103, 125],\n",
       "         [ 68, 104, 122],\n",
       "         ...,\n",
       "         [ 86, 137, 153],\n",
       "         [ 79, 131, 148],\n",
       "         [ 72, 124, 141]],\n",
       "\n",
       "        [[ 46,  81, 101],\n",
       "         [ 57,  90, 109],\n",
       "         [ 51,  84, 100],\n",
       "         ...,\n",
       "         [ 98, 144, 162],\n",
       "         [ 91, 139, 157],\n",
       "         [ 82, 130, 148]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 81, 123, 142],\n",
       "         [ 88, 128, 147],\n",
       "         [ 89, 129, 148],\n",
       "         ...,\n",
       "         [125, 161, 177],\n",
       "         [129, 160, 181],\n",
       "         [130, 158, 182]],\n",
       "\n",
       "        [[ 87, 127, 145],\n",
       "         [ 99, 139, 157],\n",
       "         [100, 140, 159],\n",
       "         ...,\n",
       "         [127, 161, 177],\n",
       "         [130, 159, 180],\n",
       "         [132, 158, 182]],\n",
       "\n",
       "        [[ 96, 136, 154],\n",
       "         [ 90, 130, 148],\n",
       "         [ 91, 131, 150],\n",
       "         ...,\n",
       "         [129, 163, 179],\n",
       "         [133, 160, 181],\n",
       "         [137, 161, 185]]],\n",
       "\n",
       "\n",
       "       [[[ 88,  95,  98],\n",
       "         [ 91,  98, 101],\n",
       "         [ 98, 101, 105],\n",
       "         ...,\n",
       "         [ 39,  34,  33],\n",
       "         [ 17,   8,   5],\n",
       "         [ 36,  27,  24]],\n",
       "\n",
       "        [[ 94,  99, 102],\n",
       "         [ 96, 101, 102],\n",
       "         [100, 104, 105],\n",
       "         ...,\n",
       "         [ 60,  55,  52],\n",
       "         [ 42,  35,  32],\n",
       "         [ 59,  50,  47]],\n",
       "\n",
       "        [[114, 118, 119],\n",
       "         [117, 119, 119],\n",
       "         [118, 120, 120],\n",
       "         ...,\n",
       "         [173, 168, 165],\n",
       "         [131, 124, 121],\n",
       "         [208, 202, 197]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[137, 171, 214],\n",
       "         [149, 183, 226],\n",
       "         [130, 162, 203],\n",
       "         ...,\n",
       "         [108, 145, 179],\n",
       "         [114, 151, 189],\n",
       "         [107, 146, 184]],\n",
       "\n",
       "        [[134, 171, 221],\n",
       "         [126, 163, 215],\n",
       "         [124, 158, 212],\n",
       "         ...,\n",
       "         [ 80, 121, 160],\n",
       "         [ 66, 108, 151],\n",
       "         [ 79, 122, 165]],\n",
       "\n",
       "        [[102, 142, 195],\n",
       "         [ 62, 101, 156],\n",
       "         [ 85, 118, 181],\n",
       "         ...,\n",
       "         [ 89, 132, 175],\n",
       "         [ 70, 112, 157],\n",
       "         [111, 155, 202]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[  2,  14,  14],\n",
       "         [ 21,  33,  33],\n",
       "         [ 11,  23,  25],\n",
       "         ...,\n",
       "         [ 67, 103, 127],\n",
       "         [ 45,  82, 110],\n",
       "         [ 17,  54,  82]],\n",
       "\n",
       "        [[ 26,  38,  38],\n",
       "         [ 24,  36,  36],\n",
       "         [ 17,  29,  31],\n",
       "         ...,\n",
       "         [ 58,  89, 114],\n",
       "         [ 61,  91, 118],\n",
       "         [ 79, 112, 138]],\n",
       "\n",
       "        [[ 25,  35,  35],\n",
       "         [  1,  11,  11],\n",
       "         [ 12,  24,  26],\n",
       "         ...,\n",
       "         [ 35,  59,  83],\n",
       "         [ 65,  88, 114],\n",
       "         [123, 146, 172]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 30,  34,  35],\n",
       "         [ 18,  23,  24],\n",
       "         [ 31,  37,  42],\n",
       "         ...,\n",
       "         [ 38,  47,  61],\n",
       "         [ 41,  49,  66],\n",
       "         [ 51,  59,  76]],\n",
       "\n",
       "        [[ 36,  41,  40],\n",
       "         [ 30,  36,  35],\n",
       "         [ 45,  52,  55],\n",
       "         ...,\n",
       "         [ 83,  90, 105],\n",
       "         [ 76,  84, 101],\n",
       "         [ 66,  74,  91]],\n",
       "\n",
       "        [[ 30,  35,  33],\n",
       "         [ 32,  38,  37],\n",
       "         [ 51,  59,  59],\n",
       "         ...,\n",
       "         [ 77,  84,  99],\n",
       "         [ 76,  84, 101],\n",
       "         [ 70,  78,  95]]],\n",
       "\n",
       "\n",
       "       [[[ 88,  95,  98],\n",
       "         [ 91,  98, 101],\n",
       "         [ 98, 101, 105],\n",
       "         ...,\n",
       "         [ 38,  33,  32],\n",
       "         [ 17,   8,   5],\n",
       "         [ 35,  26,  23]],\n",
       "\n",
       "        [[ 94,  99, 102],\n",
       "         [ 96, 101, 102],\n",
       "         [100, 104, 105],\n",
       "         ...,\n",
       "         [ 59,  54,  51],\n",
       "         [ 41,  34,  31],\n",
       "         [ 59,  50,  47]],\n",
       "\n",
       "        [[114, 118, 119],\n",
       "         [117, 119, 119],\n",
       "         [118, 120, 120],\n",
       "         ...,\n",
       "         [174, 169, 166],\n",
       "         [130, 123, 120],\n",
       "         [207, 201, 196]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[137, 171, 214],\n",
       "         [149, 183, 226],\n",
       "         [130, 162, 203],\n",
       "         ...,\n",
       "         [108, 145, 179],\n",
       "         [114, 151, 189],\n",
       "         [107, 146, 184]],\n",
       "\n",
       "        [[134, 171, 221],\n",
       "         [126, 163, 215],\n",
       "         [124, 158, 212],\n",
       "         ...,\n",
       "         [ 80, 121, 160],\n",
       "         [ 66, 108, 151],\n",
       "         [ 79, 122, 165]],\n",
       "\n",
       "        [[102, 142, 195],\n",
       "         [ 62, 101, 156],\n",
       "         [ 85, 118, 181],\n",
       "         ...,\n",
       "         [ 89, 132, 175],\n",
       "         [ 70, 112, 157],\n",
       "         [111, 155, 202]]],\n",
       "\n",
       "\n",
       "       [[[ 88,  97, 101],\n",
       "         [ 98, 107, 111],\n",
       "         [ 88,  97, 101],\n",
       "         ...,\n",
       "         [116, 121, 119],\n",
       "         [120, 127, 124],\n",
       "         [100, 107, 104]],\n",
       "\n",
       "        [[ 86,  92,  97],\n",
       "         [ 90,  99, 103],\n",
       "         [ 93,  99, 104],\n",
       "         ...,\n",
       "         [115, 120, 118],\n",
       "         [121, 126, 124],\n",
       "         [117, 124, 121]],\n",
       "\n",
       "        [[104, 109, 112],\n",
       "         [ 96, 103, 106],\n",
       "         [104, 109, 112],\n",
       "         ...,\n",
       "         [118, 124, 119],\n",
       "         [110, 116, 111],\n",
       "         [119, 125, 120]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[110, 122, 126],\n",
       "         [116, 130, 136],\n",
       "         [102, 118, 125],\n",
       "         ...,\n",
       "         [109, 117, 124],\n",
       "         [115, 124, 133],\n",
       "         [114, 123, 132]],\n",
       "\n",
       "        [[106, 118, 120],\n",
       "         [111, 123, 125],\n",
       "         [ 91, 106, 109],\n",
       "         ...,\n",
       "         [108, 118, 125],\n",
       "         [123, 132, 141],\n",
       "         [105, 114, 123]],\n",
       "\n",
       "        [[ 87,  97,  97],\n",
       "         [ 91, 103, 103],\n",
       "         [ 74,  86,  90],\n",
       "         ...,\n",
       "         [106, 116, 123],\n",
       "         [120, 129, 138],\n",
       "         [101, 110, 119]]]], dtype=uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escalar as imagens para que o valor esteja entre 0 e 1\n",
    "train_img = train_img / 255.0\n",
    "test_img = test_img / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.32941176, 0.38039216, 0.44313725],\n",
       "         [0.47058824, 0.52156863, 0.58431373],\n",
       "         [0.48235294, 0.51764706, 0.57254902],\n",
       "         ...,\n",
       "         [0.64313725, 0.61176471, 0.70196078],\n",
       "         [0.59607843, 0.54901961, 0.66666667],\n",
       "         [0.56078431, 0.50588235, 0.63921569]],\n",
       "\n",
       "        [[0.3254902 , 0.37647059, 0.43921569],\n",
       "         [0.41568627, 0.46666667, 0.52941176],\n",
       "         [0.50588235, 0.54901961, 0.60392157],\n",
       "         ...,\n",
       "         [0.64705882, 0.61960784, 0.70196078],\n",
       "         [0.55686275, 0.51764706, 0.63529412],\n",
       "         [0.50980392, 0.46666667, 0.59215686]],\n",
       "\n",
       "        [[0.3254902 , 0.38823529, 0.43921569],\n",
       "         [0.38039216, 0.43137255, 0.48627451],\n",
       "         [0.53333333, 0.57647059, 0.63137255],\n",
       "         ...,\n",
       "         [0.62352941, 0.61568627, 0.69019608],\n",
       "         [0.56470588, 0.54509804, 0.65098039],\n",
       "         [0.54509804, 0.5254902 , 0.63921569]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.4627451 , 0.3372549 , 0.29411765],\n",
       "         [0.47058824, 0.31372549, 0.26666667],\n",
       "         [0.6       , 0.38039216, 0.3372549 ],\n",
       "         ...,\n",
       "         [0.95294118, 0.93333333, 0.99215686],\n",
       "         [0.94509804, 0.90980392, 0.96078431],\n",
       "         [0.87058824, 0.83137255, 0.87843137]],\n",
       "\n",
       "        [[0.32156863, 0.18431373, 0.14509804],\n",
       "         [0.58039216, 0.41568627, 0.36862745],\n",
       "         [0.64313725, 0.41176471, 0.37254902],\n",
       "         ...,\n",
       "         [0.87058824, 0.85098039, 0.90980392],\n",
       "         [0.83529412, 0.79607843, 0.85882353],\n",
       "         [0.81960784, 0.78039216, 0.83137255]],\n",
       "\n",
       "        [[0.32941176, 0.19215686, 0.15294118],\n",
       "         [0.53333333, 0.36862745, 0.32156863],\n",
       "         [0.61960784, 0.38039216, 0.34117647],\n",
       "         ...,\n",
       "         [0.80784314, 0.78431373, 0.85098039],\n",
       "         [0.65490196, 0.61568627, 0.67843137],\n",
       "         [0.85490196, 0.81176471, 0.8745098 ]]],\n",
       "\n",
       "\n",
       "       [[[0.16862745, 0.32941176, 0.41960784],\n",
       "         [0.19607843, 0.34901961, 0.43529412],\n",
       "         [0.25882353, 0.40392157, 0.48235294],\n",
       "         ...,\n",
       "         [0.27058824, 0.4745098 , 0.5372549 ],\n",
       "         [0.2627451 , 0.4745098 , 0.54117647],\n",
       "         [0.26666667, 0.47843137, 0.54509804]],\n",
       "\n",
       "        [[0.21960784, 0.37254902, 0.45882353],\n",
       "         [0.25882353, 0.40392157, 0.49019608],\n",
       "         [0.26666667, 0.40784314, 0.47843137],\n",
       "         ...,\n",
       "         [0.3372549 , 0.5372549 , 0.6       ],\n",
       "         [0.30980392, 0.51372549, 0.58039216],\n",
       "         [0.28235294, 0.48627451, 0.55294118]],\n",
       "\n",
       "        [[0.18039216, 0.31764706, 0.39607843],\n",
       "         [0.22352941, 0.35294118, 0.42745098],\n",
       "         [0.2       , 0.32941176, 0.39215686],\n",
       "         ...,\n",
       "         [0.38431373, 0.56470588, 0.63529412],\n",
       "         [0.35686275, 0.54509804, 0.61568627],\n",
       "         [0.32156863, 0.50980392, 0.58039216]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.31764706, 0.48235294, 0.55686275],\n",
       "         [0.34509804, 0.50196078, 0.57647059],\n",
       "         [0.34901961, 0.50588235, 0.58039216],\n",
       "         ...,\n",
       "         [0.49019608, 0.63137255, 0.69411765],\n",
       "         [0.50588235, 0.62745098, 0.70980392],\n",
       "         [0.50980392, 0.61960784, 0.71372549]],\n",
       "\n",
       "        [[0.34117647, 0.49803922, 0.56862745],\n",
       "         [0.38823529, 0.54509804, 0.61568627],\n",
       "         [0.39215686, 0.54901961, 0.62352941],\n",
       "         ...,\n",
       "         [0.49803922, 0.63137255, 0.69411765],\n",
       "         [0.50980392, 0.62352941, 0.70588235],\n",
       "         [0.51764706, 0.61960784, 0.71372549]],\n",
       "\n",
       "        [[0.37647059, 0.53333333, 0.60392157],\n",
       "         [0.35294118, 0.50980392, 0.58039216],\n",
       "         [0.35686275, 0.51372549, 0.58823529],\n",
       "         ...,\n",
       "         [0.50588235, 0.63921569, 0.70196078],\n",
       "         [0.52156863, 0.62745098, 0.70980392],\n",
       "         [0.5372549 , 0.63137255, 0.7254902 ]]],\n",
       "\n",
       "\n",
       "       [[[0.34509804, 0.37254902, 0.38431373],\n",
       "         [0.35686275, 0.38431373, 0.39607843],\n",
       "         [0.38431373, 0.39607843, 0.41176471],\n",
       "         ...,\n",
       "         [0.15294118, 0.13333333, 0.12941176],\n",
       "         [0.06666667, 0.03137255, 0.01960784],\n",
       "         [0.14117647, 0.10588235, 0.09411765]],\n",
       "\n",
       "        [[0.36862745, 0.38823529, 0.4       ],\n",
       "         [0.37647059, 0.39607843, 0.4       ],\n",
       "         [0.39215686, 0.40784314, 0.41176471],\n",
       "         ...,\n",
       "         [0.23529412, 0.21568627, 0.20392157],\n",
       "         [0.16470588, 0.1372549 , 0.1254902 ],\n",
       "         [0.23137255, 0.19607843, 0.18431373]],\n",
       "\n",
       "        [[0.44705882, 0.4627451 , 0.46666667],\n",
       "         [0.45882353, 0.46666667, 0.46666667],\n",
       "         [0.4627451 , 0.47058824, 0.47058824],\n",
       "         ...,\n",
       "         [0.67843137, 0.65882353, 0.64705882],\n",
       "         [0.51372549, 0.48627451, 0.4745098 ],\n",
       "         [0.81568627, 0.79215686, 0.77254902]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5372549 , 0.67058824, 0.83921569],\n",
       "         [0.58431373, 0.71764706, 0.88627451],\n",
       "         [0.50980392, 0.63529412, 0.79607843],\n",
       "         ...,\n",
       "         [0.42352941, 0.56862745, 0.70196078],\n",
       "         [0.44705882, 0.59215686, 0.74117647],\n",
       "         [0.41960784, 0.57254902, 0.72156863]],\n",
       "\n",
       "        [[0.5254902 , 0.67058824, 0.86666667],\n",
       "         [0.49411765, 0.63921569, 0.84313725],\n",
       "         [0.48627451, 0.61960784, 0.83137255],\n",
       "         ...,\n",
       "         [0.31372549, 0.4745098 , 0.62745098],\n",
       "         [0.25882353, 0.42352941, 0.59215686],\n",
       "         [0.30980392, 0.47843137, 0.64705882]],\n",
       "\n",
       "        [[0.4       , 0.55686275, 0.76470588],\n",
       "         [0.24313725, 0.39607843, 0.61176471],\n",
       "         [0.33333333, 0.4627451 , 0.70980392],\n",
       "         ...,\n",
       "         [0.34901961, 0.51764706, 0.68627451],\n",
       "         [0.2745098 , 0.43921569, 0.61568627],\n",
       "         [0.43529412, 0.60784314, 0.79215686]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.00784314, 0.05490196, 0.05490196],\n",
       "         [0.08235294, 0.12941176, 0.12941176],\n",
       "         [0.04313725, 0.09019608, 0.09803922],\n",
       "         ...,\n",
       "         [0.2627451 , 0.40392157, 0.49803922],\n",
       "         [0.17647059, 0.32156863, 0.43137255],\n",
       "         [0.06666667, 0.21176471, 0.32156863]],\n",
       "\n",
       "        [[0.10196078, 0.14901961, 0.14901961],\n",
       "         [0.09411765, 0.14117647, 0.14117647],\n",
       "         [0.06666667, 0.11372549, 0.12156863],\n",
       "         ...,\n",
       "         [0.22745098, 0.34901961, 0.44705882],\n",
       "         [0.23921569, 0.35686275, 0.4627451 ],\n",
       "         [0.30980392, 0.43921569, 0.54117647]],\n",
       "\n",
       "        [[0.09803922, 0.1372549 , 0.1372549 ],\n",
       "         [0.00392157, 0.04313725, 0.04313725],\n",
       "         [0.04705882, 0.09411765, 0.10196078],\n",
       "         ...,\n",
       "         [0.1372549 , 0.23137255, 0.3254902 ],\n",
       "         [0.25490196, 0.34509804, 0.44705882],\n",
       "         [0.48235294, 0.57254902, 0.6745098 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.11764706, 0.13333333, 0.1372549 ],\n",
       "         [0.07058824, 0.09019608, 0.09411765],\n",
       "         [0.12156863, 0.14509804, 0.16470588],\n",
       "         ...,\n",
       "         [0.14901961, 0.18431373, 0.23921569],\n",
       "         [0.16078431, 0.19215686, 0.25882353],\n",
       "         [0.2       , 0.23137255, 0.29803922]],\n",
       "\n",
       "        [[0.14117647, 0.16078431, 0.15686275],\n",
       "         [0.11764706, 0.14117647, 0.1372549 ],\n",
       "         [0.17647059, 0.20392157, 0.21568627],\n",
       "         ...,\n",
       "         [0.3254902 , 0.35294118, 0.41176471],\n",
       "         [0.29803922, 0.32941176, 0.39607843],\n",
       "         [0.25882353, 0.29019608, 0.35686275]],\n",
       "\n",
       "        [[0.11764706, 0.1372549 , 0.12941176],\n",
       "         [0.1254902 , 0.14901961, 0.14509804],\n",
       "         [0.2       , 0.23137255, 0.23137255],\n",
       "         ...,\n",
       "         [0.30196078, 0.32941176, 0.38823529],\n",
       "         [0.29803922, 0.32941176, 0.39607843],\n",
       "         [0.2745098 , 0.30588235, 0.37254902]]],\n",
       "\n",
       "\n",
       "       [[[0.34509804, 0.37254902, 0.38431373],\n",
       "         [0.35686275, 0.38431373, 0.39607843],\n",
       "         [0.38431373, 0.39607843, 0.41176471],\n",
       "         ...,\n",
       "         [0.14901961, 0.12941176, 0.1254902 ],\n",
       "         [0.06666667, 0.03137255, 0.01960784],\n",
       "         [0.1372549 , 0.10196078, 0.09019608]],\n",
       "\n",
       "        [[0.36862745, 0.38823529, 0.4       ],\n",
       "         [0.37647059, 0.39607843, 0.4       ],\n",
       "         [0.39215686, 0.40784314, 0.41176471],\n",
       "         ...,\n",
       "         [0.23137255, 0.21176471, 0.2       ],\n",
       "         [0.16078431, 0.13333333, 0.12156863],\n",
       "         [0.23137255, 0.19607843, 0.18431373]],\n",
       "\n",
       "        [[0.44705882, 0.4627451 , 0.46666667],\n",
       "         [0.45882353, 0.46666667, 0.46666667],\n",
       "         [0.4627451 , 0.47058824, 0.47058824],\n",
       "         ...,\n",
       "         [0.68235294, 0.6627451 , 0.65098039],\n",
       "         [0.50980392, 0.48235294, 0.47058824],\n",
       "         [0.81176471, 0.78823529, 0.76862745]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5372549 , 0.67058824, 0.83921569],\n",
       "         [0.58431373, 0.71764706, 0.88627451],\n",
       "         [0.50980392, 0.63529412, 0.79607843],\n",
       "         ...,\n",
       "         [0.42352941, 0.56862745, 0.70196078],\n",
       "         [0.44705882, 0.59215686, 0.74117647],\n",
       "         [0.41960784, 0.57254902, 0.72156863]],\n",
       "\n",
       "        [[0.5254902 , 0.67058824, 0.86666667],\n",
       "         [0.49411765, 0.63921569, 0.84313725],\n",
       "         [0.48627451, 0.61960784, 0.83137255],\n",
       "         ...,\n",
       "         [0.31372549, 0.4745098 , 0.62745098],\n",
       "         [0.25882353, 0.42352941, 0.59215686],\n",
       "         [0.30980392, 0.47843137, 0.64705882]],\n",
       "\n",
       "        [[0.4       , 0.55686275, 0.76470588],\n",
       "         [0.24313725, 0.39607843, 0.61176471],\n",
       "         [0.33333333, 0.4627451 , 0.70980392],\n",
       "         ...,\n",
       "         [0.34901961, 0.51764706, 0.68627451],\n",
       "         [0.2745098 , 0.43921569, 0.61568627],\n",
       "         [0.43529412, 0.60784314, 0.79215686]]],\n",
       "\n",
       "\n",
       "       [[[0.34509804, 0.38039216, 0.39607843],\n",
       "         [0.38431373, 0.41960784, 0.43529412],\n",
       "         [0.34509804, 0.38039216, 0.39607843],\n",
       "         ...,\n",
       "         [0.45490196, 0.4745098 , 0.46666667],\n",
       "         [0.47058824, 0.49803922, 0.48627451],\n",
       "         [0.39215686, 0.41960784, 0.40784314]],\n",
       "\n",
       "        [[0.3372549 , 0.36078431, 0.38039216],\n",
       "         [0.35294118, 0.38823529, 0.40392157],\n",
       "         [0.36470588, 0.38823529, 0.40784314],\n",
       "         ...,\n",
       "         [0.45098039, 0.47058824, 0.4627451 ],\n",
       "         [0.4745098 , 0.49411765, 0.48627451],\n",
       "         [0.45882353, 0.48627451, 0.4745098 ]],\n",
       "\n",
       "        [[0.40784314, 0.42745098, 0.43921569],\n",
       "         [0.37647059, 0.40392157, 0.41568627],\n",
       "         [0.40784314, 0.42745098, 0.43921569],\n",
       "         ...,\n",
       "         [0.4627451 , 0.48627451, 0.46666667],\n",
       "         [0.43137255, 0.45490196, 0.43529412],\n",
       "         [0.46666667, 0.49019608, 0.47058824]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.43137255, 0.47843137, 0.49411765],\n",
       "         [0.45490196, 0.50980392, 0.53333333],\n",
       "         [0.4       , 0.4627451 , 0.49019608],\n",
       "         ...,\n",
       "         [0.42745098, 0.45882353, 0.48627451],\n",
       "         [0.45098039, 0.48627451, 0.52156863],\n",
       "         [0.44705882, 0.48235294, 0.51764706]],\n",
       "\n",
       "        [[0.41568627, 0.4627451 , 0.47058824],\n",
       "         [0.43529412, 0.48235294, 0.49019608],\n",
       "         [0.35686275, 0.41568627, 0.42745098],\n",
       "         ...,\n",
       "         [0.42352941, 0.4627451 , 0.49019608],\n",
       "         [0.48235294, 0.51764706, 0.55294118],\n",
       "         [0.41176471, 0.44705882, 0.48235294]],\n",
       "\n",
       "        [[0.34117647, 0.38039216, 0.38039216],\n",
       "         [0.35686275, 0.40392157, 0.40392157],\n",
       "         [0.29019608, 0.3372549 , 0.35294118],\n",
       "         ...,\n",
       "         [0.41568627, 0.45490196, 0.48235294],\n",
       "         [0.47058824, 0.50588235, 0.54117647],\n",
       "         [0.39607843, 0.43137255, 0.46666667]]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/luis/Documentos/venv/venv_deepLearn/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# criar o modelo\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(32, 32, 3)),\n",
    "    keras.layers.Dense(128, activation = tf.nn.relu),\n",
    "    keras.layers.Dense(2,activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compilar modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 1s 315us/sample - loss: 0.9151 - acc: 0.5255\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 1s 254us/sample - loss: 0.7034 - acc: 0.5485\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 0s 246us/sample - loss: 0.6846 - acc: 0.5655\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 1s 259us/sample - loss: 0.6669 - acc: 0.5830\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 0s 249us/sample - loss: 0.6729 - acc: 0.5735\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 1s 258us/sample - loss: 0.6750 - acc: 0.5810\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 1s 252us/sample - loss: 0.6629 - acc: 0.6065\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 1s 263us/sample - loss: 0.6458 - acc: 0.6135\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 1s 251us/sample - loss: 0.6399 - acc: 0.6290\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 1s 254us/sample - loss: 0.6485 - acc: 0.6120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6c5d4dbcc0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# treinar modelo\n",
    "model.fit(train_img, train_label, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 82us/sample - loss: 0.6695 - acc: 0.5836\n",
      "Test accuracy: 0.583625\n"
     ]
    }
   ],
   "source": [
    "# efici√™ncia do modelo\n",
    "test_loss, test_acc = model.evaluate(test_img, test_label)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6007606 , 0.39923942],\n",
       "       [0.45997897, 0.54002094],\n",
       "       [0.5794647 , 0.42053536],\n",
       "       ...,\n",
       "       [0.5323185 , 0.46768147],\n",
       "       [0.48925567, 0.5107444 ],\n",
       "       [0.81656086, 0.18343915]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# previsoes\n",
    "predict = model.predict(test_img)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# previs√£o √© um vetor de 2 n√∫meros onde descreve a confian√ßa que teve para cada resultado\n",
    "\n",
    "p = 89\n",
    "\n",
    "print('Predito:', class_name[np.argmax(predict[p])])\n",
    "print('Real:',class_name[test_label[p]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
