{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GcmkZiCGTudP"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r4n8aYr2yt_z"
   },
   "source": [
    "### Importar e tratar os dados LOCAIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gVYcNzMITudU"
   },
   "outputs": [],
   "source": [
    "# lista arquivos por formato\n",
    "def filtrar_arquivo(tipo):\n",
    "    path = './'\n",
    "    lst_arq = os.listdir(path) # listando novamente o diretório para verificar arquivos csv\n",
    "    return [arq for arq in lst_arq if arq[-3:] == tipo]\n",
    "\n",
    "# Separa arquivo zip caso haja outros tipos de arquivo na pasta\n",
    "lst_zip = filtrar_arquivo('zip')\n",
    "\n",
    "# extrair arquivos do zip para trabalhar\n",
    "for zp in lst_zip:\n",
    "    fzp = zipfile.ZipFile(zp)\n",
    "    fzp.extractall('./') \n",
    "    fzp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cf9mjrHiTudX"
   },
   "source": [
    "### Importar e tratar os dados no GOOGLE COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "lGxmBmqITudY",
    "outputId": "1dd69aed-2b76-4be3-d5c8-b93dcaa351d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "#  montar google driver\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "\n",
    "# extrai do Zip os csv's\n",
    "fzp = zipfile.ZipFile('/content/drive/My Drive/Colab Notebooks/cats_dogs/dataset.zip')\n",
    "fzp.extractall('.') \n",
    "fzp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tuG-KPZtTudd"
   },
   "outputs": [],
   "source": [
    "# dog = 0\n",
    "# cat = 1\n",
    "class_name = ['dog','cat']\n",
    "\n",
    "dir_img_train = 'dataset/train/*.jpg'\n",
    "dir_img_test = 'dataset/test/*.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kcyfLehOTudg"
   },
   "outputs": [],
   "source": [
    "def convert_img_array(lst):\n",
    "    \"\"\"\n",
    "    lista diretorios com imagens e convertem array\n",
    "    \n",
    "    \"\"\"\n",
    "    lst_img, lst_label=[],[]\n",
    "    for d in glob(lst):\n",
    "        lst_img.append(cv2.imread(d))\n",
    "        if 'dog' in d:\n",
    "            lst_label.append('0')\n",
    "        elif 'cat' in d:\n",
    "            lst_label.append('1')\n",
    "    return np.array(lst_img), np.array(lst_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2iY1BAlBTudj"
   },
   "outputs": [],
   "source": [
    "# gerando dados de trainos e test\n",
    "train_img, train_label = convert_img_array(dir_img_train)\n",
    "test_img, test_label = convert_img_array(dir_img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AYJi5IEKTudm",
    "outputId": "c49f64bb-3ecb-4b85-b1a7-be3033f803ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img.shape\n",
    "#print('Training dataset: ', x_train.shape, y_train.shape)\n",
    "#print('Validation dataset: ', x_val.shape, y_val.shape)\n",
    "#print('Test dataset: ', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8zwFpJnLTuds",
    "outputId": "446f2cc8-8daf-488c-d834-110811122f12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yfju4SLZTudv",
    "outputId": "31eaf81f-a67d-4771-b578-dd8006cee68e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 32, 32, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IH1DZOGLTudz",
    "outputId": "a2d273ae-5f5e-4622-ca1c-778a27d926e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YmSgXYQrTud3"
   },
   "outputs": [],
   "source": [
    "# escalar as imagens para que o valor esteja entre 0 e 1\n",
    "train_img = train_img / 255.0\n",
    "test_img = test_img / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ujo5wUFxTud8"
   },
   "source": [
    "### Classificação com Keras\n",
    "\n",
    "Melhor acurácia utilizando optimizer('sgd') = 0.763"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kMLDQrloTud9",
    "outputId": "76daafaa-665f-4f64-8aae-7fdbd0f4f086"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow e tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ \n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "#!pip install -U --ignore-installed tensorboardcolab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "5LgK7Un4TueA",
    "outputId": "fa44481a-c3b3-40e6-bb31-c7d84c65da75"
   },
   "outputs": [],
   "source": [
    "# Estaciar Modelo\n",
    "model = Sequential()\n",
    "\n",
    "# Camada de Convolução\n",
    "# As convoluções funcionam como filtros que enxergam pequenos quadrados e \n",
    "# vão “escorregando” por toda a imagem captando os traços mais marcantes.\n",
    "model.add(Conv2D(32,(5,5),padding='same', input_shape = (32, 32, 3), activation=tf.nn.relu))\n",
    "model.add(Conv2D(64,(5,5),padding='same', activation=tf.nn.relu))\n",
    "\n",
    "# Camada de Polling\n",
    "# Basicamente serve para simplificar a imformação da camada anterior\n",
    "# Pega as cacteristicas principais da imagem\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# camada de Dropout\n",
    "# Regularização é modificação feita em um algoritmo de aprendizagem com o objetivo de reduzir o \n",
    "# erro de generalização, mas não necessariamente o erro de treinamento \n",
    "model.add(Dropout(0.45))\n",
    "\n",
    "# Flattening\n",
    "# Ela basicamente opera uma transformação na matrix da imagem, alterando seu \n",
    "# formato para um array. Por exemplo, uma imagem em grayscale de 32x32 \n",
    "# será transformada para um array de 1024 posições.\n",
    "model.add(Flatten())\n",
    "\n",
    "# Full conection\n",
    "# neurônios tradicionais\n",
    "model.add(Dense(50, activation = tf.nn.relu))\n",
    "\n",
    "# camada de Dropout\n",
    "# Eliminação aleatória de neurônios durante o processo de aprendizagem, \n",
    "# para evitar a sobreadaptação aos dados (overfitting)\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "# saida da rede\n",
    "# gato ou cachorro\n",
    "model.add(Dense(2, activation = tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "G5qn1RasTueD",
    "outputId": "305bdb27-01e9-468e-b606-93b37946d1b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 32, 32, 32)        2432      \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 32, 32, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 50)                819250    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 873,048\n",
      "Trainable params: 873,048\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# O comando summary() mostra algumas informações sobre as camadas do seu modelo. \n",
    "# Podemos ver as dimensões de cada camada e os parâmetros aprendidos em cada etapa.\n",
    "model.summary()\n",
    "\n",
    "# compilar modelo\n",
    "model.compile(optimizer='sgd', \n",
    "              loss=losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-dLiKHuMTueH",
    "outputId": "6383317a-3158-4cbe-fb20-e5bddf708235"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 8000 samples\n",
      "Epoch 1/5\n",
      "  32/8000 [..............................] - ETA: 30s"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": " Cast string to int64 is not supported\n\t [[node loss/dense_11_loss/Cast (defined at /home/luis/Documentos/venv/venv_deepLearn/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_distributed_function_4071]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-7f85ad28f103>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m                    \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                    \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                    \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                   )\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/venv/venv_deepLearn/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/Documentos/venv/venv_deepLearn/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/venv/venv_deepLearn/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/venv/venv_deepLearn/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/venv/venv_deepLearn/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/venv/venv_deepLearn/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/venv/venv_deepLearn/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/venv/venv_deepLearn/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/venv/venv_deepLearn/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/venv/venv_deepLearn/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/Documentos/venv/venv_deepLearn/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/Documentos/venv/venv_deepLearn/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m:  Cast string to int64 is not supported\n\t [[node loss/dense_11_loss/Cast (defined at /home/luis/Documentos/venv/venv_deepLearn/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_distributed_function_4071]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "# treinar modelo\n",
    "start = datetime.now()\n",
    "\n",
    "\n",
    "# reduz o parâmetro da taxa de aprendizagem (learning rate) se não houver \n",
    "# melhoras em determinado número de epocas\n",
    "# útil para encontrar o mínimo global.\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=5, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "log_dir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "earlystop = EarlyStopping(patience=10)\n",
    "#callbacks = [learning_rate_reduction, earlystop,tensorboard_callback]\n",
    "\n",
    "\n",
    "treino = model.fit(x = train_img, \n",
    "                   y = train_label,\n",
    "                   batch_size = 32,\n",
    "                   epochs = 5,\n",
    "                   validation_data = (train_img, train_label),   \n",
    "                   callbacks= [tensorboard_callback]\n",
    "                  )\n",
    "\n",
    "\n",
    "print('')\n",
    "print('Tempo decorrido para treinar o modelo: ', datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 19473), started 0:32:38 ago. (Use '!kill 19473' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-87cce07c0fc59560\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-87cce07c0fc59560\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "OeZvb_KLG4Km",
    "outputId": "1da3802f-2e5c-4aa3-8bc6-a3b8951e9239"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eficiência do modelo\n",
      "2000/2000 [==============================] - 0s 217us/sample - loss: 0.5061 - acc: 0.7640\n",
      "Acurácia: 0.764\n",
      "Perda: 0.5061219804286957\n"
     ]
    }
   ],
   "source": [
    "# Eficiência do modelo\n",
    "print('')\n",
    "print('Eficiência do modelo')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_img, test_label)\n",
    "print('Acurácia:', test_acc)\n",
    "print('Perda:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "NMVAgdMEefEO",
    "outputId": "bcf55202-a9f7-4ad4-f4e0-04de2a65e04e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: \n",
      "Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  \"Adding an axes using the same arguments as a previous axes \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHoAAACTCAYAAABBEg2uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkCx0gSBZ6AJBstAFgmShCwTJQhcI/j9axEqfxbuUXAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 504x1008 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# previsoes\n",
    "predict = model.predict_classes(test_img)\n",
    "\n",
    "plt.figure(figsize=(7,14))\n",
    "\n",
    "random_num = np.random.randint(0, len(test_img))\n",
    "img = test_img[random_num]\n",
    "\n",
    "plt.subplot(6,4,1)\n",
    "\n",
    "p = predict[random_num]\n",
    "predito =  str(class_name[p])\n",
    "real = str(class_name[int(test_label[p])])\n",
    "\n",
    "plt.subplot(6,4,1)\n",
    "plt.margins(x = 20, y = 20)\n",
    "plt.title('Predição: ' + predito + '\\n'+ 'Real:'+ real)\n",
    "plt.imshow(img.reshape(32, 32,3), cmap=plt.get_cmap('gray'));\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ufaOoMcpTue1"
   },
   "source": [
    "### Classificação com Machine Learning\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_UppQGNXTue1"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mp7NZPePTue4"
   },
   "outputs": [],
   "source": [
    "# padroniza a entrada com esse reshape\n",
    "# convert de 3d para 2d\n",
    "def _reshape(ds):\n",
    "    return ds.reshape(len(ds),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "leDF2vOyTue7"
   },
   "outputs": [],
   "source": [
    "x_train = _reshape(train_img)\n",
    "y_test = _reshape(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2sawx_CGTue-"
   },
   "source": [
    "#### Modelo SVM \n",
    "\n",
    "Melhor acurácia = 0.62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vl_VhY0ZTue_"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "OQaxDzyATufB",
    "outputId": "bf6174f5-c4df-4244-85ee-869457020b3d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# accuracy testada do modelo\n",
    "# 'linear' =  0.5935\n",
    "# 'poly' = 0.566\n",
    "# 'rbf' = 0.6195\n",
    "# 'sigmoid' = 0.5885\n",
    "\n",
    "model_svm = SVC(kernel='rbf')\n",
    "model_svm.fit(x_train, train_label)\n",
    "\n",
    "predicted = model_svm.predict(y_test)\n",
    "accuracy_score(test_label, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "97uzDqSLTufE"
   },
   "source": [
    "#### Regressão Logistica\n",
    "\n",
    "Melhor acurácia = 0.597 com 'sag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YYTuzSPTufE"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hEs42voXTufI"
   },
   "outputs": [],
   "source": [
    "model_log = LogisticRegression(solver='sag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "HS7ptmXLTufM",
    "outputId": "6dec68ae-c73b-42f3-d04f-d1748d6f4c96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.595"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_log.fit(x_train, train_label)\n",
    "pred_log1 = model_log.predict(y_test)\n",
    "accuracy_score(test_label, pred_log1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z_WOT8UHTufP"
   },
   "source": [
    "#### Floresta aleatória (Random Florest)\n",
    "\n",
    "Melhor acurácia = 0.5795"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QiP2F8_nTufQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "moUZTkRBTufS"
   },
   "outputs": [],
   "source": [
    "model_rd = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "Z_vwHN49TufW",
    "outputId": "27c34748-c740-4d23-da64-6ecc9c32d2a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5795"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rd.fit(x_train, train_label)\n",
    "pred_rd = model_rd.predict(y_test)\n",
    "accuracy_score(test_label, pred_rd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k6CpE7INTufZ"
   },
   "source": [
    "#### Naives Bayes\n",
    "\n",
    "Melhor acurácia = 0.5795"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pWKDzdi8Tufb"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vyttU4QMTufe"
   },
   "outputs": [],
   "source": [
    "model_nb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AK5wvvJrTufh",
    "outputId": "a2fe6a09-4121-4fe0-830c-2c56ff90f1c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5795"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nb.fit(x_train, train_label)\n",
    "pred_nb = model_rd.predict(y_test)\n",
    "accuracy_score(test_label, pred_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kAnIP3Y3Tufm"
   },
   "source": [
    "#### K-Nearest Neighbors (KNN)\n",
    "\n",
    "Melhor acurácia = 0.582"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hkQcRs9_Tufn"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H1khD8ZBTufp"
   },
   "outputs": [],
   "source": [
    "model_knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "j8rgx2M8Tufs",
    "outputId": "793e1a9f-efa4-4498-c226-00e28f1632b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5825"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn.fit(x_train, train_label)\n",
    "pred_knn = model_knn.predict(y_test)\n",
    "accuracy_score(test_label, pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ZcYiV0kTufv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ufaOoMcpTue1"
   ],
   "name": "tf_classifica_gatos_cachorros.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
